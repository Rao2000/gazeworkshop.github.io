---
layout: layout_2021
urltitle:  "GAZE 2021: Gaze Estimation and Prediction in the Wild"
title: "GAZE 2021: Gaze Estimation and Prediction in the Wild"
categories: cvpr, workshop, computer vision, robotics, machine learning, natural language processing, gaze estimation
permalink: /2021/
favicon: /2021/img/icon.jpg
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row">
  <div class="col-xs-12">
    <center><h1>Gaze Estimation and Prediction in the Wild</h1></center>
    <center><h2>CVPR 2021 Workshop, Virtual</h2></center>
    <center>Date TBD, half-day</center>
  </div>
</div><br>

<div class="row">
  <div class="col-xs-12"><a class="anchor" id="intro"></a>
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
The 3rd International Workshop on Gaze Estimation and Prediction in the Wild (GAZE 2021) at <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a> aims to encourage and highlight novel strategies for eye gaze estimation and prediction with a focus on robustness and accuracy in extended parameter spaces, both spatially and temporally.
This is expected to be achieved by applying novel neural network architectures, incorporating anatomical insights and constraints, introducing new and challenging datasets, and exploiting multi-modal training.
Specifically, the workshop topics include (but are not limited to):
    </p>
    <p>
      The topics of this workshop include but are not limited to:
    </p>
    <ul>
      <li>Reformulating eye detection, gaze estimation, and gaze prediction pipelines with deep networks.</li>
      <li>Applying geometric and anatomical constraints into the training of (sparse or dense) deep networks.</li>
      <li>Leveraging additional cues such as contexts from face region and head pose information.</li>
      <li>Developing adversarial methods to deal with conditions where current methods fail (illumination, appearance, etc.).</li>
      <li>Exploring attention mechanisms to predict the point of regard.</li>
      <li>Designing new accurate measures to account for rapid eye gaze movement.</li>
      <li>Novel methods for temporal gaze estimation and prediction including Bayesian methods.</li>
      <li>Integrating differentiable components into 3D gaze estimation frameworks.</li>
      <li>Robust estimation from different data modalities such as RGB, depth, head pose, and eye region landmarks.</li>
      <li>Generic gaze estimation method for handling extreme head poses and gaze directions.</li>
      <li>Temporal information usage for eye tracking to provide consistent gaze estimation on the screen.</li>
      <li>Personalization of gaze estimators with few-shot learning.</li>
      <li>Semi-/weak-/un-/self- supervised leraning methods, domain adaptation methods, and other novel methods towards improved representation learning from eye/face region images or gaze target region images.</li>
    </ul>
We will be hosting 3 invited speakers and holding 2 deep learning challenges for the topic of gaze estimation. We will also be accepting the submission of full unpublished papers as done in previous versions of the workshop. These papers will be peer-reviewed via a double-blind process, and will be published in the official workshop proceedings and be presented at the workshop itself. More information will be provided as soon as possible.
  </div>
</div> <br>

<div class="row">
  <div class="col-xs-12 panel-group"><a class="anchor" id="calls"></a>
    <h2>Call for Contributions</h2>
    <br>
    <div class="panel panel-default">
      <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-papers" style="cursor:pointer;">
        <h3 style="margin:0;">Full Workshop Papers</h3>
      </div>
      <div id="call-papers" class="panel-collapse collapse in" data-parent="#call">
        <div class="panel-body">
          <p>
	    <span style="font-weight:500;">Submission:</span> We invite authors to submit unpublished papers (8-page <a href="http://iccv2021.thecvf.com/node/4#submission-guidelines" target="_blank">ICCV format</a>) to our workshop, to be presented at a poster session upon acceptance. All submissions will go through a double-blind review process. All contributions must be submitted (along with supplementary materials, if any) at
	    <a href="https://cmt3.research.microsoft.com/GAZE2021/Submission/Index" target="_blank" title="CMT Submission System for GAZE 2021">this CMT link</a>.
	  </p>
	  <p>
	    Accepted papers will be published in the official ICCV Workshops proceedings and the Computer Vision Foundation (CVF) Open Access archive.
	  </p>
	  <p>
	    <span style="font-weight:500;">Note:</span> Authors of previously rejected main conference submissions are also welcome to submit their work to our workshop. When doing so, you must submit the previous reviewers' comments (named as <code>previous_reviews.pdf</code>) and a letter of changes (named as <code>letter_of_changes.pdf</code>) as part of your supplementary materials to clearly demonstrate the changes made to address the comments made by previous reviewers.
	    <!--Due to potential clashes with the main conference reviewing schedule, we will accept simultaneous submissions to the ICCV main conference and GAZE Workshop. Simultaneous submissions are otherwise disallowed.-->
          </p>
        </div>
      </div>
    </div>
    <br>
    <!--
    <div class="panel panel-default">
      <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-ea" style="cursor:pointer;">
        <h3 style="margin:0;">Extended Abstracts</h3>
      </div>
      <div id="call-ea" class="panel-collapse collapse in" data-parent="#call">
        <div class="panel-body">
          <p>
            In addition to regular papers, we also invite extended abstracts of ongoing or published work (<i>e.g.</i> related papers on ECCV main track). The extended abstracts will not be published or made available to the public (we will only list titles on our website) but will rather be presented during our poster session. We see this as an opportunity for authors to promote their work to an interested audience to gather valuable feedback.
          </p>
	  <p>
	    Further details on how this poster session will occur online, is to be decided. In general, we will be following the main ECCV conference guidelines and organization in organizing the presentation of all posters.
          </p>
          <p>Extended abstracts are limited to six pages and must be created using the <a href="https://eccv2020.eu/author-instructions/" target="_blank">official ECCV format</a>. The submission must be sent to <a href="mailto:openeyes.workshop@gmail.com">openeyes.workshop@gmail.com</a> by the deadline (July 17th).
          </p>
          <p>
            We will evaluate and notify authors of acceptance as soon as possible (evaluation on a rolling basis until the deadline) after receiving their extended abstract submission.
          </p>
        </div>
      </div>
    </div>
    <br>
    -->
    <div class="panel panel-default">
      <div class="panel-heading" data-toggle="collapse" data-parent="#call" href="#call-challenge" style="cursor:pointer;">
        <h3 style="margin:0;">GAZE 2021 Challenges</h3>
      </div>
      <div id="call-challenge" class="panel-collapse collapse in" data-parent="#call">
        <div class="panel-body">
	  <p>
	    The GAZE 2021 Challenges are hosted on Codalab, and can be found at:
	  </p>
	  <ul>
	    <li>ETH-XGaze Challenge: <a href="https://competitions.codalab.org/competitions/28930">https://competitions.codalab.org/competitions/28930</a></li>
	    <li>EVE Challenge: <a href="https://competitions.codalab.org/competitions/28954">https://competitions.codalab.org/competitions/28954</a></li>
	  </ul>
	  <p>
            More information on the respective challenges can be found on their pages.
	  </p>
        </div>
      </div>
    </div>
  </div>
</div><br>

<div class="row">
  <div class="col-xs-12"><a class="anchor" id="dates"></a>
    <h2>Important Dates</h2>
    <br>
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>March 21, 2021 (23:59 Pacific time)</td>
	  <td><span class="countdown" reference="21 Mar 2021 23:59:59 PST"></span></td>
        </tr>
        <tr>
          <td>ETH-XGaze &amp; EVE Challenges Released</td>
          <td>February 13, 2021</td>
        </tr>
        <tr>
          <td>Paper Reviews Deadline</td>
          <td>Early April, 2021 (tentative)</td>
        </tr>
        <tr>
          <td>Notification to Authors</td>
          <td>Mid April, 2021 (tentative)</td>
        </tr>
        <tr>
          <td>Camera-Ready Deadline</td>
          <td>Late April, 2021 (tentative)</td>
        </tr>
        <tr>
          <td>ETH-XGaze &amp; EVE Challenges Closed</td>
          <td>May 28, 2021 (23:59 UTC)</td>
	  <td><span class="countdown" reference="28 May 2021 23:59:59 UTC"></span></td>
        </tr>
        <tr id="schedule">
          <td>Finalized Workshop Program</td>
          <td>Mid May, 2021 (tentative)</td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>

<div class="row">
  <div class="col-xs-12"><a class="anchor" id="organizers"></a>
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-1"></div>
  <div class="col-xs-2">
    <a href="https://hyungjinchang.wordpress.com/">
      <img class="people-pic" src="{{ "img/people/hj.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://hyungjinchang.wordpress.com/">Hyung Jin Chang</a>
      <h6>University of Birmingham</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://ait.ethz.ch/people/zhang/">
      <img class="people-pic" src="{{ "img/people/xz.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ait.ethz.ch/people/zhang/">Xucong Zhang</a>
      <h6>ETH Zürich</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://ait.ethz.ch/people/spark/">
      <img class="people-pic" src="{{ "img/people/sp.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ait.ethz.ch/people/spark/">Seonwook Park</a>
      <h6>Lunit Inc.</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://research.nvidia.com/person/shalini-gupta">
      <img class="people-pic" src="{{ "img/people/sdm.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://research.nvidia.com/person/shalini-gupta">Shalini De Mello</a>
      <h6>NVIDIA Research</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://thabobeeler.com/">
      <img class="people-pic" src="{{ "img/people/tb.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://thabobeeler.com/">Thabo Beeler</a>
      <h6>Google</h6>
    </div>
  </div>
  <div class="col-xs-1"></div>
</div>
<br>
<div class="row">
  <div class="col-xs-1"></div>
  <div class="col-xs-2">
    <a href="https://www.ecse.rpi.edu/~qji/">
      <img class="people-pic" src="{{ "img/people/qj.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.ecse.rpi.edu/~qji/">Qiang Ji</a>
      <h6>Rensselaer Polytechnic Institute</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://ait.ethz.ch/people/hilliges/">
      <img class="people-pic" src="{{ "img/people/oh.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ait.ethz.ch/people/hilliges/">Otmar Hilliges</a>
      <h6>ETH Zürich</h6>
    </div>
  </div>
  <div class="col-xs-2">
    <a href="https://www.cs.bham.ac.uk/~leonarda/">
      <img class="people-pic" src="{{ "img/people/al.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.cs.bham.ac.uk/~leonarda/">Aleš Leonardis</a>
      <h6>University of Birmingham</h6>
    </div>
  </div>
</div><br>


<div class="row">
  <div class="col-xs-12"><a class="anchor" id="sponsors"></a>
    <h2>Workshop sponsored by:</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-2"></div>
  <div class="col-xs-4 sponsor">
    <a href="https://www.nvidia.com/"><img src="img/nvidia.jpg" /></a>
  </div>
  <div class="col-xs-4 sponsor">
    <a href="https://www.tobii.com/"><img src="img/tobii.jpg" /></a>
  </div>
  <div class="col-xs-2"></div>
</div>

